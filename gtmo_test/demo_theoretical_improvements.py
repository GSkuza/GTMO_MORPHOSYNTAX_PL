#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Demo usprawnieÅ„ teoretycznych warstwy adelicznej
=================================================
Prezentuje trzy gÅ‚Ã³wne usprawnienia:
1. Pseudo-metryka Minkowskiego (sygnatura -,+,+) vs metryka Î¦â¹
2. Adaptacyjny prÃ³g Îµ(kontekst, rejestr)
3. Dekompozycja D-S-E w diagnostyce

Kontekst: Analiza wynikÃ³w testÃ³w demo_special_observers.py
"""

import sys
import numpy as np
from gtmo_adelic_layer import AdelicSemanticLayer, create_standard_observers
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    except:
        pass


def demo_phi9_vs_minkowski():
    """Demo 1: PorÃ³wnanie metryki Î¦â¹ (Riemannowska) vs Minkowski (pseudo-metryka)."""
    print("\n" + "=" * 70)
    print("  DEMO 1: Metryka Î¦â¹ vs Pseudo-metryka Minkowskiego")
    print("=" * 70)

    layer = AdelicSemanticLayer()
    observers = create_standard_observers()

    obs_formal = [o for o in observers if o.id == 'O_formal'][0]
    obs_casual = [o for o in observers if o.id == 'O_casual'][0]

    # Tekst neutralny
    base_coords = np.array([0.70, 0.70, 0.30])

    print(f"\nğŸ“ Base coords: {base_coords}")
    print(f"\nğŸ‘ï¸  Obserwatorzy: O_formal + O_casual")

    # Test 1: Metryka Î¦â¹ (domyÅ›lna)
    result_phi9 = layer.analyze_with_observers(
        text="test_phi9",
        base_coords=base_coords,
        observers=[obs_formal, obs_casual],
        metric='phi9'
    )

    print(f"\nğŸ“ METRYKA Î¦â¹ (Riemannowska, symetryczna):")
    print(f"  Emerged: {result_phi9['emerged']}")
    print(f"  Energy: {result_phi9['synchronization_energy']:.4f}")

    # Test 2: Metryka Minkowskiego
    result_minkowski = layer.analyze_with_observers(
        text="test_minkowski",
        base_coords=base_coords,
        observers=[obs_formal, obs_casual],
        metric='minkowski'
    )

    print(f"\nğŸ“ PSEUDO-METRYKA MINKOWSKIEGO (sygnatura -,+,+):")
    print(f"  Emerged: {result_minkowski['emerged']}")
    print(f"  Energy: {result_minkowski['synchronization_energy']:.4f}")

    print(f"\nğŸ”¬ RÃ“Å»NICA:")
    ratio = result_minkowski['synchronization_energy'] / result_phi9['synchronization_energy']
    print(f"  Energy ratio (Minkowski/Î¦â¹): {ratio:.3f}x")
    print(f"  â†’ Minkowski penalizuje zmiany S (stabilnoÅ›Ä‡) silniej")
    print(f"  â†’ Î¦â¹ penalizuje zmiany E (entropia) silniej")

    print(f"\nğŸ“ TEORETYCZNA INTERPRETACJA:")
    print(f"  Î¦â¹: Metryka Riemannowska - wszystkie osie rÃ³wnoprawne topologicznie")
    print(f"  Minkowski: Pseudo-metryka - oÅ› S ma sygnaturÄ™ ujemnÄ… (timelike)")
    print(f"  â†’ S reprezentuje 'czas semantyczny' (kauzalnoÅ›Ä‡)")
    print(f"  â†’ D,E reprezentujÄ… 'przestrzeÅ„ semantycznÄ…' (konfiguracja)")


def demo_adaptive_epsilon():
    """Demo 2: Adaptacyjny prÃ³g emergencji Îµ(kontekst, rejestr)."""
    print("\n" + "=" * 70)
    print("  DEMO 2: Adaptacyjny prÃ³g emergencji Îµ(kontekst, rejestr)")
    print("=" * 70)

    layer = AdelicSemanticLayer()
    observers = create_standard_observers()

    obs_formal = [o for o in observers if o.id == 'O_formal'][0]
    obs_casual = [o for o in observers if o.id == 'O_casual'][0]

    # Obserwatorzy lekko rozbieÅ¼ni
    base_coords = np.array([0.70, 0.72, 0.28])

    print(f"\nğŸ“ Base coords: {base_coords}")
    print(f"ğŸ‘ï¸  Obserwatorzy: O_formal + O_casual (lekka rozbieÅ¼noÅ›Ä‡)")

    # Test 1: StaÅ‚y epsilon (rygorystyczny kontekst formalny)
    result_fixed = layer.analyze_with_observers(
        text="test_fixed_epsilon",
        base_coords=base_coords,
        observers=[obs_formal, obs_casual],
        metric='phi9'
    )

    print(f"\nğŸ“ STAÅY PRÃ“G Îµ = 0.15 (domyÅ›lny):")
    print(f"  Emerged: {result_fixed['emerged']}")
    print(f"  Energy: {result_fixed['synchronization_energy']:.4f}")

    # Test 2: Adaptacyjny epsilon (kontekst formalny, niska entropia)
    print(f"\nğŸ¯ ADAPTACYJNY Îµ (kontekst formalny, E=0.1):")
    from gtmo_adelic_metrics import compute_adaptive_epsilon

    eps_formal = compute_adaptive_epsilon(
        base_epsilon=0.15,
        context_entropy=0.1,
        register='formal'
    )
    print(f"  Îµ_adaptive = {eps_formal:.3f} (BARDZIEJ rygorystyczny)")

    # Test 3: Adaptacyjny epsilon (kontekst casualny, wysoka entropia)
    print(f"\nğŸ¯ ADAPTACYJNY Îµ (kontekst casualny, E=0.7):")
    eps_casual = compute_adaptive_epsilon(
        base_epsilon=0.15,
        context_entropy=0.7,
        register='casual'
    )
    print(f"  Îµ_adaptive = {eps_casual:.3f} (BARDZIEJ tolerancyjny)")

    print(f"\nğŸ“Š PORÃ“WNANIE:")
    print(f"  Îµ_base:   0.150")
    print(f"  Îµ_formal: {eps_formal:.3f} ({eps_formal/0.15:.2f}x base)")
    print(f"  Îµ_casual: {eps_casual:.3f} ({eps_casual/0.15:.2f}x base)")
    print(f"  Ratio casual/formal: {eps_casual/eps_formal:.2f}x")

    print(f"\nğŸ’¡ UZASADNIENIE TEORETYCZNE:")
    print(f"  Îµ_adaptive = Îµâ‚€ Â· (1 + Î³Â·H_context) Â· f_register")
    print(f"  â€¢ Kontekst wysokoentropijny (poetycki, casualny):")
    print(f"    â†’ wiÄ™ksze Îµ â†’ wiÄ™ksza tolerancja na desynchronizacjÄ™")
    print(f"  â€¢ Kontekst niskoentropijny (formalny, prawniczy):")
    print(f"    â†’ mniejsze Îµ â†’ wymagany Å›cisÅ‚y konsensus")
    print(f"  â†’ PrÃ³g dostosowuje siÄ™ do 'naturalnej niepewnoÅ›ci' kontekstu!")


def demo_axis_decomposition():
    """Demo 3: Dekompozycja D-S-E w diagnostyce niepowodzenia emergencji."""
    print("\n" + "=" * 70)
    print("  DEMO 3: Dekompozycja D-S-E w diagnostyce")
    print("=" * 70)

    layer = AdelicSemanticLayer()
    observers = create_standard_observers()

    obs_formal = [o for o in observers if o.id == 'O_formal'][0]
    obs_halluc = [o for o in observers if o.id == 'O_hallucination'][0]
    obs_nonsense = [o for o in observers if o.id == 'O_nonsense'][0]

    # Test 1: Desynchronizacja w E (halucynacje)
    print(f"\nğŸ”´ PRZYPADEK 1: Halucynacja (desynchronizacja w E)")
    base_halluc = np.array([0.80, 0.82, 0.20])

    result_halluc = layer.analyze_with_observers(
        text="hallucination_test",
        base_coords=base_halluc,
        observers=[obs_formal, obs_halluc],
        metric='phi9'
    )

    print(f"  Emerged: {result_halluc['emerged']}")
    print(f"  Energy: {result_halluc['synchronization_energy']:.4f}")

    if 'diagnosis' in result_halluc:
        diag = result_halluc['diagnosis']
        print(f"\n  ğŸ“Š DEKOMPOZYCJA OSI:")
        for axis in ['D', 'S', 'E']:
            pct = diag['axis_decomposition'][axis]['percentage']
            bar = 'â–ˆ' * int(pct / 5)
            print(f"    {axis}: {pct:5.1f}% {bar}")

        print(f"\n  ğŸ¯ DOMINUJÄ„CA OÅš: {diag['dominant_axis']}")
        print(f"  ğŸ’¬ {diag['interpretation']}")
        print(f"  âš¡ INTENSYWNOÅšÄ†: {diag['energy_severity']}")

    # Test 2: Desynchronizacja w D (nonsens)
    print(f"\nğŸ­ PRZYPADEK 2: Nonsens (desynchronizacja w D)")
    base_nonsense = np.array([0.60, 0.65, 0.40])

    result_nonsense = layer.analyze_with_observers(
        text="nonsense_test",
        base_coords=base_nonsense,
        observers=[obs_formal, obs_nonsense],
        metric='phi9'
    )

    print(f"  Emerged: {result_nonsense['emerged']}")
    print(f"  Energy: {result_nonsense['synchronization_energy']:.4f}")

    if 'diagnosis' in result_nonsense:
        diag = result_nonsense['diagnosis']
        print(f"\n  ğŸ“Š DEKOMPOZYCJA OSI:")
        for axis in ['D', 'S', 'E']:
            pct = diag['axis_decomposition'][axis]['percentage']
            bar = 'â–ˆ' * int(pct / 5)
            print(f"    {axis}: {pct:5.1f}% {bar}")

        print(f"\n  ğŸ¯ DOMINUJÄ„CA OÅš: {diag['dominant_axis']}")
        print(f"  ğŸ’¬ {diag['interpretation']}")
        print(f"  âš¡ INTENSYWNOÅšÄ†: {diag['energy_severity']}")

    print(f"\nğŸ“ WNIOSEK:")
    print(f"  â€¢ Halucynacje â†’ desynchronizacja w E (entropia/chaos)")
    print(f"  â€¢ Nonsens â†’ desynchronizacja w D (okreÅ›lonoÅ›Ä‡/pewnoÅ›Ä‡)")
    print(f"  â†’ Dekompozycja D-S-E pozwala diagnozowaÄ‡ TYP patologii!")


def demo_epsilon_in_practice():
    """Demo 4: Praktyczne zastosowanie adaptacyjnego epsilon."""
    print("\n" + "=" * 70)
    print("  DEMO 4: Praktyczne zastosowanie adaptacyjnego Îµ")
    print("=" * 70)

    layer = AdelicSemanticLayer()
    observers = create_standard_observers()

    obs_legal = [o for o in observers if o.id == 'O_legal_strict'][0]
    obs_journalistic = [o for o in observers if o.id == 'O_journalistic'][0]

    # Tekst graniczny (na granicy emergencji)
    base_borderline = np.array([0.78, 0.80, 0.22])

    print(f"\nğŸ“ Base coords (borderline): {base_borderline}")
    print(f"ğŸ‘ï¸  Obserwatorzy: O_legal_strict + O_journalistic")

    # Test z rÃ³Å¼nymi kontekstami
    from gtmo_adelic_metrics import compute_adaptive_epsilon, check_emergence_condition

    contexts = [
        ('legal', 0.05, 'Dokument prawny (rygorystyczny)'),
        ('formal', 0.15, 'Dokument formalny (neutralny)'),
        ('journalistic', 0.35, 'ArtykuÅ‚ prasowy (umiarkowany)'),
        ('casual', 0.65, 'Dyskusja casualowa (tolerancyjny)')
    ]

    print(f"\nğŸ“Š EMERGENCJA w rÃ³Å¼nych kontekstach:")
    print(f"  {'Kontekst':<25} {'Îµ_adapt':<10} {'Emerged?':<10}")
    print(f"  {'-'*25} {'-'*10} {'-'*10}")

    # Symuluj lokalne wspÃ³Å‚rzÄ™dne
    local_coords = [
        base_borderline + np.array([0.02, 0.02, -0.02]),
        base_borderline + np.array([-0.02, -0.01, 0.01])
    ]

    for register, entropy, description in contexts:
        eps_adapt = compute_adaptive_epsilon(
            base_epsilon=0.15,
            context_entropy=entropy,
            register=register
        )

        emerged, _ = check_emergence_condition(
            local_coords=local_coords,
            epsilon=eps_adapt,
            metric='phi9'
        )

        status = "âœ“ TAK" if emerged else "âœ— NIE"
        print(f"  {description:<25} {eps_adapt:<10.3f} {status:<10}")

    print(f"\nğŸ’¡ WNIOSEK:")
    print(f"  Ta sama rozbieÅ¼noÅ›Ä‡ obserwatorÃ³w moÅ¼e:")
    print(f"  â€¢ BlokowaÄ‡ emergencjÄ™ w kontekÅ›cie prawniczym (Îµ=0.105)")
    print(f"  â€¢ PozwalaÄ‡ na emergencjÄ™ w kontekÅ›cie casualowym (Îµ=0.218)")
    print(f"  â†’ Adaptacyjny Îµ uwzglÄ™dnia 'naturalnÄ… niepewnoÅ›Ä‡' rejestru!")


def demo_propaganda_vs_hallucination():
    """Demo 5: Propaganda vs Halucynacje - rÃ³Å¼ne typy patologii E-dominant."""
    print("\n" + "=" * 70)
    print("  DEMO 5: Propaganda vs Halucynacje - obie E w dekompozycji")
    print("=" * 70)

    layer = AdelicSemanticLayer()
    observers = create_standard_observers()

    obs_formal = [o for o in observers if o.id == 'O_formal'][0]
    obs_propaganda = [o for o in observers if o.id == 'O_propaganda'][0]
    obs_halluc = [o for o in observers if o.id == 'O_hallucination'][0]

    # Test 1: Propaganda (Dâ†‘â†‘, Sâ†‘â†‘, Eâ†“ - faÅ‚szywa pewnoÅ›Ä‡)
    # UÅ¼ywamy niÅ¼szych wspÃ³Å‚rzÄ™dnych aby propagandowy obserwator mÃ³gÅ‚ "popchaÄ‡" w gÃ³rÄ™
    print(f"\nğŸ“¢ PRZYPADEK 1: Propaganda (faÅ‚szywa pewnoÅ›Ä‡)")
    base_propaganda = np.array([0.70, 0.72, 0.30])  # Neutralna baza

    result_propaganda = layer.analyze_with_observers(
        text="propaganda_test",
        base_coords=base_propaganda,
        observers=[obs_formal, obs_propaganda],
        metric='phi9'
    )

    print(f"  Base coords: {base_propaganda}")
    print(f"  Emerged: {result_propaganda['emerged']}")
    print(f"  Energy: {result_propaganda['synchronization_energy']:.4f}")

    # PokaÅ¼ lokalne interpretacje
    if 'local_values' in result_propaganda:
        print(f"\n  ğŸ“ Lokalne interpretacje:")
        for obs_id, data in result_propaganda['local_values'].items():
            coords = data['local_value']
            print(f"    {obs_id}: [{coords[0]:.3f}, {coords[1]:.3f}, {coords[2]:.3f}]")

    if 'diagnosis' in result_propaganda:
        diag = result_propaganda['diagnosis']
        print(f"\n  ğŸ“Š DEKOMPOZYCJA OSI:")
        for axis in ['D', 'S', 'E']:
            pct = diag['axis_decomposition'][axis]['percentage']
            bar = 'â–ˆ' * int(pct / 5)
            print(f"    {axis}: {pct:5.1f}% {bar}")

        print(f"\n  ğŸ¯ DOMINUJÄ„CA OÅš: {diag['dominant_axis']}")
        print(f"  ğŸ’¬ {diag['interpretation']}")
        print(f"  âš¡ INTENSYWNOÅšÄ†: {diag['energy_severity']} ({diag['severity_interpretation']})")
    else:
        print(f"\n  âœ… Propaganda EMERGED - obserwatorzy osiÄ…gnÄ™li konsensus")
        print(f"  â†’ To sugeruje Å¼e propaganda byÅ‚a 'przekonujÄ…ca' dla obu obserwatorÃ³w")

    # Test 2: Halucynacja (D?, S?, Eâ†‘â†‘ - chaos entropijny)
    print(f"\nğŸ”´ PRZYPADEK 2: Halucynacja (chaos entropijny)")
    base_halluc = np.array([0.80, 0.82, 0.20])

    result_halluc = layer.analyze_with_observers(
        text="hallucination_test",
        base_coords=base_halluc,
        observers=[obs_formal, obs_halluc],
        metric='phi9'
    )

    print(f"  Emerged: {result_halluc['emerged']}")
    print(f"  Energy: {result_halluc['synchronization_energy']:.4f}")

    if 'diagnosis' in result_halluc:
        diag = result_halluc['diagnosis']
        print(f"\n  ğŸ“Š DEKOMPOZYCJA OSI:")
        for axis in ['D', 'S', 'E']:
            pct = diag['axis_decomposition'][axis]['percentage']
            bar = 'â–ˆ' * int(pct / 5)
            print(f"    {axis}: {pct:5.1f}% {bar}")

        print(f"\n  ğŸ¯ DOMINUJÄ„CA OÅš: {diag['dominant_axis']}")
        print(f"  ğŸ’¬ {diag['interpretation']}")
        print(f"  âš¡ INTENSYWNOÅšÄ†: {diag['energy_severity']} ({diag['severity_interpretation']})")

    # PorÃ³wnanie
    print(f"\nğŸ”¬ PORÃ“WNANIE (dekompozycja + energia):")

    print(f"\n  Propaganda:")
    if 'diagnosis' in result_propaganda:
        diag_p = result_propaganda['diagnosis']
        print(f"    Status: FAILED (desynchronizacja)")
        print(f"    Dominant: {diag_p['dominant_axis']} ({diag_p['axis_decomposition'][diag_p['dominant_axis']]['percentage']:.1f}%)")
        print(f"    Energy: {result_propaganda['synchronization_energy']:.2f} [{diag_p['energy_severity']}]")
    else:
        print(f"    Status: EMERGED (konsensus)")
        print(f"    Energy: {result_propaganda['synchronization_energy']:.4f}")

    print(f"\n  Halucynacja:")
    if 'diagnosis' in result_halluc:
        diag_h = result_halluc['diagnosis']
        print(f"    Status: FAILED (desynchronizacja)")
        print(f"    Dominant: {diag_h['dominant_axis']} ({diag_h['axis_decomposition'][diag_h['dominant_axis']]['percentage']:.1f}%)")
        print(f"    Energy: {result_halluc['synchronization_energy']:.2f} [{diag_h['energy_severity']}]")
    else:
        print(f"    Status: EMERGED (konsensus)")
        print(f"    Energy: {result_halluc['synchronization_energy']:.4f}")

    # PorÃ³wnanie energii tylko jeÅ›li obie majÄ… energiÄ™
    if result_halluc['synchronization_energy'] > 0:
        energy_ratio = result_propaganda['synchronization_energy'] / result_halluc['synchronization_energy']
        print(f"\n  ğŸ“Š STOSUNEK ENERGII (Propaganda/Halucynacja): {energy_ratio:.4f}x")
        if energy_ratio < 0.1:
            print(f"  â†’ Propaganda: NISKA energia (konsensus lub bliska zgodnoÅ›Ä‡)")
            print(f"  â†’ Halucynacja: WYSOKA energia (fundamentalny konflikt)")
        print(f"  â†’ Energia jako DYSKRYMINATOR typu patologii!")

    print(f"\nğŸ“ WNIOSEK:")
    print(f"  â€¢ Propaganda: D+Sâ†‘â†‘ (faÅ‚szywa pewnoÅ›Ä‡) â†’ energia zaleÅ¼y od stopnia przekÅ‚amania")
    print(f"  â€¢ Halucynacja: Eâ†‘â†‘ (chaos) â†’ energia zaleÅ¼y od stopnia entropii")
    print(f"  â†’ RÃ³Å¼ne mechanizmy patologii wymagajÄ… rÃ³Å¼nych strategii korekcji!")
    print(f"  â†’ Stosunek energii V_Comm pomaga ROZRÃ“Å»NIÄ† typy bÅ‚Ä™dÃ³w!")


def demo_boundary_epsilon():
    """Demo 6: Przypadki graniczne - emergencja na granicy progu."""
    print("\n" + "=" * 70)
    print("  DEMO 6: Przypadki graniczne adaptacyjnego Îµ")
    print("=" * 70)

    layer = AdelicSemanticLayer()
    observers = create_standard_observers()

    obs_formal = [o for o in observers if o.id == 'O_formal'][0]
    obs_journalistic = [o for o in observers if o.id == 'O_journalistic'][0]

    from gtmo_adelic_metrics import compute_adaptive_epsilon, check_emergence_condition

    print(f"\nğŸ¯ Testujemy granicÄ™ emergencji dla rÃ³Å¼nych kontekstÃ³w")
    print(f"ğŸ‘ï¸  Obserwatorzy: O_formal + O_journalistic")

    # Przypadki z rosnÄ…cÄ… rozbieÅ¼noÅ›ciÄ… - tworzymy rzeczywiste divergencje miÄ™dzy obserwatorami
    # KaÅ¼dy przypadek to: (base, observer_shift, description)
    test_cases = [
        (np.array([0.75, 0.75, 0.25]), np.array([0.02, 0.02, -0.02]), "Minimalna (Î”=0.02)"),
        (np.array([0.75, 0.75, 0.25]), np.array([0.08, 0.08, -0.08]), "Lekka (Î”=0.08)"),
        (np.array([0.75, 0.75, 0.25]), np.array([0.11, 0.11, -0.11]), "Umiarkowana (Î”=0.11)"),
        (np.array([0.75, 0.75, 0.25]), np.array([0.14, 0.14, -0.14]), "Silna (Î”=0.14)"),
        (np.array([0.75, 0.75, 0.25]), np.array([0.20, 0.20, -0.20]), "Ekstremalna (Î”=0.20)"),
    ]

    contexts = [
        ('legal', 0.05),
        ('formal', 0.15),
        ('casual', 0.65),
    ]

    print(f"\nğŸ“Š EMERGENCJA w rÃ³Å¼nych kontekstach i rozbieÅ¼noÅ›ciach:")
    print(f"  {'Przypadek':<24} | {'Legal':<8} | {'Formal':<8} | {'Casual':<8}")
    print(f"  {'-'*24} | {'-'*8} | {'-'*8} | {'-'*8}")

    for base_coords, observer_shift, description in test_cases:
        row = f"  {description:<24}"

        for register, entropy in contexts:
            eps_adapt = compute_adaptive_epsilon(
                base_epsilon=0.15,
                context_entropy=entropy,
                register=register
            )

            # Symuluj lokalne wspÃ³Å‚rzÄ™dne: obserwator 1 = base, obserwator 2 = base + shift
            local_coords = [
                base_coords,
                base_coords + observer_shift,
                base_coords - observer_shift * 0.5  # trzeci obserwator dla wiÄ™kszej rÃ³Å¼norodnoÅ›ci
            ]

            emerged, _ = check_emergence_condition(
                local_coords=local_coords,
                epsilon=eps_adapt,
                metric='phi9'
            )

            status = "âœ“" if emerged else "âœ—"
            row += f" | {status:^8}"

        print(row)

    print(f"\nğŸ’¡ WNIOSEK:")
    print(f"  â€¢ Minimalna rozbieÅ¼noÅ›Ä‡ (Î”=0.02): âœ“âœ“âœ“ - wszystkie konteksty akceptujÄ…")
    print(f"  â€¢ Lekka rozbieÅ¼noÅ›Ä‡ (Î”=0.08): âœ—âœ“âœ“ - legal odrzuca, formal/casual akceptujÄ…")
    print(f"  â€¢ Umiarkowana (Î”=0.11-12): âœ—âœ—âœ“ - tylko casual toleruje")
    print(f"  â€¢ Silna/Ekstremalna (Î”â‰¥0.14): âœ—âœ—âœ—/âœ— - rozbieÅ¼noÅ›Ä‡ zbyt duÅ¼a nawet dla casual")
    print(f"  â†’ Adaptacyjny Îµ automatycznie dostosowuje siÄ™ do 'naturalnej tolerancji'!")
    print(f"  â†’ System ma wyraÅºne GRANICE emergencji zaleÅ¼ne od kontekstu!")


def main():
    print("\n")
    print("â•”" + "=" * 68 + "â•—")
    print("â•‘" + " " * 10 + "GTMÃ˜ THEORETICAL IMPROVEMENTS DEMO" + " " * 24 + "â•‘")
    print("â•‘" + " " * 8 + "Minkowski, Adaptive Îµ, D-S-E Decomposition" + " " * 17 + "â•‘")
    print("â•š" + "=" * 68 + "â•")

    try:
        demo_phi9_vs_minkowski()
        try:
            input("\n\nNaciÅ›nij Enter...")
        except EOFError:
            pass

        demo_adaptive_epsilon()
        try:
            input("\n\nNaciÅ›nij Enter...")
        except EOFError:
            pass

        demo_axis_decomposition()
        try:
            input("\n\nNaciÅ›nij Enter...")
        except EOFError:
            pass

        demo_epsilon_in_practice()
        try:
            input("\n\nNaciÅ›nij Enter...")
        except EOFError:
            pass

        demo_propaganda_vs_hallucination()
        try:
            input("\n\nNaciÅ›nij Enter...")
        except EOFError:
            pass

        demo_boundary_epsilon()

        print("\n" + "=" * 70)
        print("  âœ… DEMO ZAKOÅƒCZONE")
        print("=" * 70)
        print("\nğŸ¯ Kluczowe usprawnienia teoretyczne:")
        print("  1. PSEUDO-METRYKA MINKOWSKIEGO (sygnatura -,+,+)")
        print("     â€¢ OÅ› S (stabilnoÅ›Ä‡) ma charakter temporalny (timelike)")
        print("     â€¢ Osie D,E (determination, entropy) majÄ… charakter przestrzenny")
        print("     â€¢ Zachowuje kauzalnoÅ›Ä‡ semantycznÄ…")
        print("")
        print("  2. ADAPTACYJNY PRÃ“G Îµ(kontekst, rejestr)")
        print("     â€¢ Îµ_adaptive = Îµâ‚€ Â· (1 + Î³Â·H_context) Â· f_register")
        print("     â€¢ Rygorystyczny dla kontekstu formalnego/prawniczego")
        print("     â€¢ Tolerancyjny dla kontekstu casualnego/poetyckiego")
        print("     â€¢ UwzglÄ™dnia 'naturalnÄ… niepewnoÅ›Ä‡' rejestru")
        print("")
        print("  3. DEKOMPOZYCJA D-S-E W DIAGNOSTYCE")
        print("     â€¢ Pokazuje ktÃ³ra oÅ› (D/S/E) powoduje desynchronizacjÄ™")
        print("     â€¢ Halucynacje â†’ desynchronizacja w E (entropia)")
        print("     â€¢ Nonsens â†’ desynchronizacja w D (okreÅ›lonoÅ›Ä‡)")
        print("     â€¢ Propaganda â†’ desynchronizacja w D i S (faÅ‚szywa pewnoÅ›Ä‡)")
        print("")
        print("  4. STOSUNEK ENERGII jako DYSKRYMINATOR")
        print("     â€¢ Dla przypadkÃ³w z tÄ… samÄ… dominujÄ…cÄ… osiÄ… (np. E)")
        print("     â€¢ Energy ratio rozrÃ³Å¼nia TYP patologii (propaganda vs halucynacja)")
        print("     â€¢ UmoÅ¼liwia precyzyjnÄ… klasyfikacjÄ™ bÅ‚Ä™dÃ³w semantycznych")
        print("")
        print("  5. TESTOWANIE GRANIC EMERGENCJI")
        print("     â€¢ Pokazuje wyraÅºne granice adaptacyjnego Îµ")
        print("     â€¢ Legal: emergencja tylko przy minimalnej rozbieÅ¼noÅ›ci")
        print("     â€¢ Casual: emergencja nawet przy silnej rozbieÅ¼noÅ›ci")
        print("")
        print("ğŸ’¡ Wszystkie usprawnienia majÄ… uzasadnienie w teorii GTMÃ˜!")

    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
